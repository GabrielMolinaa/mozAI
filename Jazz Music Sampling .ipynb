{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import music21\n",
    "from glob import glob\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras_utils\n",
    "import play\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = glob('Rap/*.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    print(\"Obtendo notas\")\n",
    "    notes = []\n",
    "    for file in songs:\n",
    "        # converting .mid file to stream object\n",
    "        midi = converter.parse(file)\n",
    "        notes_to_parse = []\n",
    "        try:\n",
    "            # Given a single stream, partition into a part for each unique instrument\n",
    "            parts = instrument.partitionByInstrument(midi)\n",
    "        except:\n",
    "            pass\n",
    "        if parts: # if parts has instrument parts \n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else:\n",
    "            notes_to_parse = midi.flat.notes\n",
    "    \n",
    "        for element in notes_to_parse: \n",
    "            if isinstance(element, note.Note):\n",
    "                # if element is a note, extract pitch\n",
    "                notes.append(str(element.pitch))\n",
    "            elif(isinstance(element, chord.Chord)):\n",
    "                # if element is a chord, append the normal form of the \n",
    "                # chord (a list of integers) to the list of notes. \n",
    "                notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "    with open('data/notes', 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    return notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab): \n",
    "    sequence_length = 100\n",
    "\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i: i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        network_output.append(note_to_int[sequence_out])\n",
    "    \n",
    "    n_patterns = len(network_input)\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    network_output = tf.keras.utils.to_categorical(network_output)\n",
    "    \n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_in, n_vocab): \n",
    "    \"\"\"Create the model architecture\"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=network_in.shape[1:], return_sequences=True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output, epochs): \n",
    "    \"\"\"\n",
    "    Train the neural network\n",
    "    \"\"\"\n",
    "    # Create checkpoint to save the best model weights.\n",
    "    filepath = './modelo_teste.h5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=32, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network():\n",
    "    \"\"\"\n",
    "    Obter notas\n",
    "    Gerar sequências de entrada e saída\n",
    "    Criar um modelo\n",
    "    Treinar o modelo para as épocas fornecidas\n",
    "    \"\"\"\n",
    "    epochs = 50\n",
    "    batch_size = 32\n",
    "\n",
    "    notes = get_notes()\n",
    "    print('Notas processadas')\n",
    "\n",
    "    n_vocab = len(set(notes))\n",
    "    print('Vocabulário gerado')\n",
    "\n",
    "    network_in, network_out = prepare_sequences(notes, n_vocab)\n",
    "    print('Entrada e Saída processadas')\n",
    "\n",
    "    model = create_network(network_in, n_vocab)\n",
    "    print('Modelo criado')\n",
    "    print('Treinamento em andamento')\n",
    "    \n",
    "    train(model, network_in, network_out, epochs)\n",
    "    print('Treinamento concluído')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtendo notas\n",
      "Notas processadas\n",
      "Vocabulário gerado\n",
      "Entrada e Saída processadas\n",
      "Modelo criado\n",
      "Treinamento em andamento\n",
      "Epoch 1/50\n",
      "16/16 [==============================] - 14s 320ms/step - loss: 3.8499\n",
      "Epoch 2/50\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 3.4116\n",
      "Epoch 3/50\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 3.2289\n",
      "Epoch 4/50\n",
      "16/16 [==============================] - 5s 313ms/step - loss: 3.1408\n",
      "Epoch 5/50\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 3.0654\n",
      "Epoch 6/50\n",
      "16/16 [==============================] - 5s 314ms/step - loss: 2.9735\n",
      "Epoch 7/50\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 2.8722\n",
      "Epoch 8/50\n",
      "16/16 [==============================] - 5s 325ms/step - loss: 2.7833\n",
      "Epoch 9/50\n",
      "16/16 [==============================] - 5s 343ms/step - loss: 2.7359\n",
      "Epoch 10/50\n",
      "16/16 [==============================] - 5s 319ms/step - loss: 2.6522\n",
      "Epoch 11/50\n",
      "16/16 [==============================] - 5s 328ms/step - loss: 2.6106\n",
      "Epoch 12/50\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 2.4932\n",
      "Epoch 13/50\n",
      "16/16 [==============================] - 6s 350ms/step - loss: 2.4383\n",
      "Epoch 14/50\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 2.4474\n",
      "Epoch 15/50\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 2.3595\n",
      "Epoch 16/50\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 2.3180\n",
      "Epoch 17/50\n",
      "16/16 [==============================] - 5s 339ms/step - loss: 2.2504\n",
      "Epoch 18/50\n",
      "16/16 [==============================] - 7s 461ms/step - loss: 2.1753\n",
      "Epoch 19/50\n",
      "16/16 [==============================] - 5s 325ms/step - loss: 2.1519\n",
      "Epoch 20/50\n",
      "16/16 [==============================] - 7s 436ms/step - loss: 2.0690\n",
      "Epoch 21/50\n",
      "16/16 [==============================] - 5s 337ms/step - loss: 2.0415\n",
      "Epoch 22/50\n",
      "16/16 [==============================] - 5s 326ms/step - loss: 2.0221\n",
      "Epoch 23/50\n",
      "16/16 [==============================] - 5s 341ms/step - loss: 1.9958\n",
      "Epoch 24/50\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 1.9257\n",
      "Epoch 25/50\n",
      "16/16 [==============================] - 5s 325ms/step - loss: 1.8773\n",
      "Epoch 26/50\n",
      "16/16 [==============================] - 5s 332ms/step - loss: 1.8819\n",
      "Epoch 27/50\n",
      "16/16 [==============================] - 5s 329ms/step - loss: 1.8294\n",
      "Epoch 28/50\n",
      "16/16 [==============================] - 5s 342ms/step - loss: 1.8013\n",
      "Epoch 29/50\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 1.7688\n",
      "Epoch 30/50\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 1.6636\n",
      "Epoch 31/50\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 1.6748\n",
      "Epoch 32/50\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 1.6021\n",
      "Epoch 33/50\n",
      "16/16 [==============================] - 5s 322ms/step - loss: 1.5124\n",
      "Epoch 34/50\n",
      "16/16 [==============================] - 6s 347ms/step - loss: 1.5582\n",
      "Epoch 35/50\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 1.4439\n",
      "Epoch 36/50\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 1.4133\n",
      "Epoch 37/50\n",
      "16/16 [==============================] - 5s 332ms/step - loss: 1.5190\n",
      "Epoch 38/50\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 1.3459\n",
      "Epoch 39/50\n",
      "16/16 [==============================] - 5s 314ms/step - loss: 1.2950\n",
      "Epoch 40/50\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 1.2356\n",
      "Epoch 41/50\n",
      "16/16 [==============================] - 5s 311ms/step - loss: 1.1663\n",
      "Epoch 42/50\n",
      "16/16 [==============================] - 5s 315ms/step - loss: 1.0992\n",
      "Epoch 43/50\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 1.0239\n",
      "Epoch 44/50\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.9047\n",
      "Epoch 45/50\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.8321\n",
      "Epoch 46/50\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.7438\n",
      "Epoch 47/50\n",
      "16/16 [==============================] - 5s 322ms/step - loss: 0.6325\n",
      "Epoch 48/50\n",
      "16/16 [==============================] - 5s 323ms/step - loss: 0.5005\n",
      "Epoch 49/50\n",
      "16/16 [==============================] - 5s 335ms/step - loss: 0.4338\n",
      "Epoch 50/50\n",
      "16/16 [==============================] - 5s 320ms/step - loss: 0.3526\n",
      "Treinamento concluído\n"
     ]
    }
   ],
   "source": [
    "### Train the model \n",
    "model = train_network()\n",
    "model.save_weights('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputSequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    sequence_length = 100\n",
    "    network_input = []\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "    \n",
    "    network_input = np.reshape(network_input, (len(network_input), 100, 1))\n",
    "    \n",
    "    return (network_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab, temperature=1.0):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # Pick a random integer\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    \n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    pattern = list(network_input[start])\n",
    "    prediction_output = []\n",
    "    \n",
    "    print('Generating notes........')\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(500):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        pattern = np.array(pattern)\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        # Ajuste da temperatura\n",
    "        prediction = model.predict(prediction_input, verbose=0)[0]\n",
    "        prediction = np.log(prediction) / temperature\n",
    "        exp_preds = np.exp(prediction)\n",
    "        prediction = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        # Escolha aleatória com base nas probabilidades ajustadas\n",
    "        index = np.random.choice(len(prediction), p=prediction)\n",
    "        result = int_to_note[index]\n",
    "\n",
    "        # Storing the predicted output\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern = np.append(pattern, index)\n",
    "        pattern = pattern[1:]\n",
    "\n",
    "    print('Notes Generated...')\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    \n",
    "    print('Saving Output file as midi....')\n",
    "\n",
    "    midi_stream.write('midi', fp='test_output4.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    print('Initiating music generation process.......')\n",
    "    \n",
    "    network_input = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "    normalized_input = network_input / float(n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    print('Loading Model weights.....')\n",
    "    model.load_weights('./modelo_teste.h5')\n",
    "    print('Model Loaded')\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating music generation process.......\n",
      "Loading Model weights.....\n",
      "Model Loaded\n",
      "Generating notes........\n",
      "Notes Generated...\n",
      "Saving Output file as midi....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file test_output4.mid loaded!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\Desktop\\mozAI\\mozAI\\play.py:38\u001b[0m, in \u001b[0;36mplay_midi\u001b[1;34m(midi_file)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     play_music(midi_file)\n\u001b[0;32m     39\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[39m# if user hits Ctrl/C then exit\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     \u001b[39m# (works only in console mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\Desktop\\mozAI\\mozAI\\play.py:24\u001b[0m, in \u001b[0;36mplay_music\u001b[1;34m(music_file)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mwhile\u001b[39;00m pygame\u001b[39m.\u001b[39mmixer\u001b[39m.\u001b[39mmusic\u001b[39m.\u001b[39mget_busy():\n\u001b[0;32m     23\u001b[0m     \u001b[39m# check if playback has finished\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     clock\u001b[39m.\u001b[39;49mtick(\u001b[39m30\u001b[39;49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Gabriel Molina\\Desktop\\mozAI\\mozAI\\Jazz Music Sampling .ipynb Célula 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Gabriel%20Molina/Desktop/mozAI/mozAI/Jazz%20Music%20Sampling%20.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m play\u001b[39m.\u001b[39;49mplay_midi(\u001b[39m'\u001b[39;49m\u001b[39mtest_output4.mid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\Desktop\\mozAI\\mozAI\\play.py:44\u001b[0m, in \u001b[0;36mplay_midi\u001b[1;34m(midi_file)\u001b[0m\n\u001b[0;32m     43\u001b[0m pygame\u001b[39m.\u001b[39mmixer\u001b[39m.\u001b[39mmusic\u001b[39m.\u001b[39mstop()\n\u001b[1;32m---> 44\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mSystemExit\u001b[39;00m\n",
      "\u001b[1;31mSystemExit\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2093\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2094\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2095\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2096\u001b[0m                                                      value))\n\u001b[0;32m   2097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2098\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2099\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1428\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[1;32m-> 1428\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1429\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1430\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1319\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1316\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1317\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1318\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1320\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1323\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1172\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m   1164\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1165\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m   1170\u001b[0m ):\n\u001b[0;32m   1171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1172\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1173\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1175\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1062\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m   1060\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m   1061\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m   1063\u001b[0m )\n\u001b[0;32m   1065\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m   1066\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Gabriel Molina\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\ultratb.py:1130\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[0;32m   1131\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "play.play_midi('test_output4.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
