{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import music21\n",
    "from glob import glob\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import play\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Bidirectional, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.layers import Activation, Dense, LSTM, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicas = glob('Rap/*.mid')\n",
    "musicas = musicas[::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_notas():\n",
    "    print(\"Obtendo notas\")\n",
    "    notas = []\n",
    "    for arquivo in musicas:\n",
    "        # convertendo o arquivo .mid para um objeto stream\n",
    "        midi = converter.parse(arquivo)\n",
    "        notas_para_analisar = []\n",
    "        \n",
    "        try:\n",
    "            # Dada uma única stream, particiona em uma parte para cada instrumento único\n",
    "            partes = instrument.partitionByInstrument(midi)\n",
    "        except:\n",
    "            pass\n",
    "        if partes:  # se houver partes de instrumento\n",
    "            notas_para_analisar = partes.parts[0].recurse()\n",
    "        else:\n",
    "            notas_para_analisar = midi.flat.notes\n",
    "    \n",
    "        for elemento in notas_para_analisar: \n",
    "            if isinstance(elemento, note.Note):\n",
    "                # se o elemento for uma nota, extraia o tom\n",
    "                notas.append(str(elemento.pitch))\n",
    "            elif(isinstance(elemento, chord.Chord)):\n",
    "                # se o elemento for um acorde, adicione a forma normal do acorde \n",
    "                # (uma lista de inteiros) à lista de notas\n",
    "                notas.append('.'.join(str(n) for n in elemento.normalOrder))\n",
    "    with open('dados/notas', 'wb') as caminho_arquivo:\n",
    "        pickle.dump(notas, caminho_arquivo)\n",
    "    return notas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_sequencias(notas, n_vocab): \n",
    "    comprimento_sequencia = 100\n",
    "\n",
    "    nomes_tons = sorted(set(item for item in notas))\n",
    "    tom_para_inteiro = dict((tom, numero) for numero, tom in enumerate(nomes_tons))\n",
    "\n",
    "    entrada_rede = []\n",
    "    saida_rede = []\n",
    "\n",
    "    for i in range(0, len(notas) - comprimento_sequencia, 1):\n",
    "        sequencia_entrada = notas[i: i + comprimento_sequencia]\n",
    "        sequencia_saida = notas[i + comprimento_sequencia]\n",
    "        entrada_rede.append([tom_para_inteiro[char] for char in sequencia_entrada])\n",
    "        saida_rede.append(tom_para_inteiro[sequencia_saida])\n",
    "    \n",
    "    numero_padroes = len(entrada_rede)\n",
    "    entrada_rede = np.reshape(entrada_rede, (numero_padroes, comprimento_sequencia, 1))\n",
    "    entrada_rede = entrada_rede / float(n_vocab)\n",
    "    saida_rede = tf.keras.utils.to_categorical(saida_rede)\n",
    "    \n",
    "    return (entrada_rede, saida_rede)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_rede_neural(entrada_rede, n_vocab): \n",
    "    modelo = Sequential()\n",
    "    modelo.add(LSTM(128, input_shape=entrada_rede.shape[1:], return_sequences=True))\n",
    "    modelo.add(Dropout(0.2))\n",
    "    modelo.add(LSTM(128, return_sequences=True))\n",
    "    modelo.add(Flatten())\n",
    "    modelo.add(Dense(256))\n",
    "    modelo.add(Dense(256))\n",
    "    modelo.add(Dropout(0.3))\n",
    "    modelo.add(Dense(n_vocab))\n",
    "    modelo.add(Activation('softmax'))\n",
    "    modelo.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "    return modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def treinar(modelo, entrada_rede, saida_rede, epocas): \n",
    "\n",
    "    caminho_arquivo = './modelo_teste.h5'\n",
    "    ponto_verificacao = ModelCheckpoint(caminho_arquivo, monitor='loss', verbose=0, save_best_only=True)\n",
    "    \n",
    "    historico = modelo.fit(entrada_rede, saida_rede, epochs=epocas, batch_size=32, callbacks=[ponto_verificacao])\n",
    "\n",
    "    # Plotando a perda (Loss)\n",
    "    plt.plot(historico.history['loss'])\n",
    "    plt.title('Perda no Treinamento')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_rede_neural():\n",
    "    \"\"\"\n",
    "    Obter notas\n",
    "    Gerar sequências de entrada e saída\n",
    "    Criar um modelo\n",
    "    Treinar o modelo para as épocas fornecidas\n",
    "    \"\"\"\n",
    "    epocas = 100\n",
    "    \n",
    "    notas = obter_notas()\n",
    "    print('Notas processadas')\n",
    "\n",
    "    n_vocab = len(set(notas))\n",
    "    print('Vocabulário gerado')\n",
    "\n",
    "    entrada_rede, saida_rede = preparar_sequencias(notas, n_vocab)\n",
    "    print('Entrada e Saída processadas')\n",
    "\n",
    "    modelo = criar_rede_neural(entrada_rede, n_vocab)\n",
    "    print('Modelo criado')\n",
    "    print('Treinamento em andamento')\n",
    "    \n",
    "    treinar(modelo, entrada_rede, saida_rede, epocas)\n",
    "    print('Treinamento concluído')\n",
    "    return modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtendo notas\n",
      "Notas processadas\n",
      "Vocabulário gerado\n",
      "Entrada e Saída processadas\n",
      "Modelo criado\n",
      "Treinamento em andamento\n",
      "Epoch 1/100\n",
      "323/323 [==============================] - 37s 106ms/step - loss: 4.5667\n",
      "Epoch 2/100\n",
      "323/323 [==============================] - 34s 105ms/step - loss: 4.2279\n",
      "Epoch 3/100\n",
      "323/323 [==============================] - 34s 106ms/step - loss: 3.9636\n",
      "Epoch 4/100\n",
      "323/323 [==============================] - 35s 107ms/step - loss: 3.7489\n",
      "Epoch 5/100\n",
      "323/323 [==============================] - 36s 111ms/step - loss: 3.4996\n",
      "Epoch 6/100\n",
      "323/323 [==============================] - 35s 108ms/step - loss: 3.2074\n",
      "Epoch 7/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 2.9536\n",
      "Epoch 8/100\n",
      "323/323 [==============================] - 34s 106ms/step - loss: 2.7382\n",
      "Epoch 9/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 2.5409\n",
      "Epoch 10/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 2.3148\n",
      "Epoch 11/100\n",
      "323/323 [==============================] - 35s 108ms/step - loss: 2.0730\n",
      "Epoch 12/100\n",
      "323/323 [==============================] - 34s 106ms/step - loss: 1.8378\n",
      "Epoch 13/100\n",
      "323/323 [==============================] - 34s 104ms/step - loss: 1.5349\n",
      "Epoch 14/100\n",
      "323/323 [==============================] - 35s 107ms/step - loss: 1.2971\n",
      "Epoch 15/100\n",
      "323/323 [==============================] - 36s 111ms/step - loss: 1.0309\n",
      "Epoch 16/100\n",
      "323/323 [==============================] - 34s 105ms/step - loss: 0.8170\n",
      "Epoch 17/100\n",
      "323/323 [==============================] - 34s 106ms/step - loss: 0.6608\n",
      "Epoch 18/100\n",
      "323/323 [==============================] - 34s 105ms/step - loss: 0.5593\n",
      "Epoch 19/100\n",
      "323/323 [==============================] - 34s 104ms/step - loss: 0.4419\n",
      "Epoch 20/100\n",
      "323/323 [==============================] - 34s 104ms/step - loss: 0.3768\n",
      "Epoch 21/100\n",
      "323/323 [==============================] - 35s 108ms/step - loss: 0.3191\n",
      "Epoch 22/100\n",
      "323/323 [==============================] - 34s 106ms/step - loss: 0.2978\n",
      "Epoch 23/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 0.2684\n",
      "Epoch 24/100\n",
      "323/323 [==============================] - 36s 110ms/step - loss: 0.2850\n",
      "Epoch 25/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 0.2342\n",
      "Epoch 26/100\n",
      "323/323 [==============================] - 35s 107ms/step - loss: 0.2192\n",
      "Epoch 27/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 0.2102\n",
      "Epoch 28/100\n",
      "323/323 [==============================] - 36s 110ms/step - loss: 0.2084\n",
      "Epoch 29/100\n",
      "323/323 [==============================] - 37s 113ms/step - loss: 0.1803\n",
      "Epoch 30/100\n",
      "323/323 [==============================] - 35s 108ms/step - loss: 0.1767\n",
      "Epoch 31/100\n",
      "323/323 [==============================] - 35s 108ms/step - loss: 0.1796\n",
      "Epoch 32/100\n",
      "323/323 [==============================] - 36s 110ms/step - loss: 0.1911\n",
      "Epoch 33/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 0.1617\n",
      "Epoch 34/100\n",
      "323/323 [==============================] - 36s 110ms/step - loss: 0.1733\n",
      "Epoch 35/100\n",
      "323/323 [==============================] - 36s 110ms/step - loss: 0.1538\n",
      "Epoch 36/100\n",
      "323/323 [==============================] - 35s 109ms/step - loss: 0.1534\n",
      "Epoch 37/100\n",
      "323/323 [==============================] - 36s 113ms/step - loss: 0.1417\n",
      "Epoch 38/100\n",
      "323/323 [==============================] - 36s 112ms/step - loss: 0.1863\n",
      "Epoch 39/100\n",
      "323/323 [==============================] - 36s 113ms/step - loss: 0.1629\n",
      "Epoch 40/100\n",
      "323/323 [==============================] - 36s 112ms/step - loss: 0.1650\n",
      "Epoch 41/100\n",
      "323/323 [==============================] - 36s 112ms/step - loss: 0.1335\n",
      "Epoch 42/100\n",
      "323/323 [==============================] - 36s 112ms/step - loss: 0.1489\n",
      "Epoch 43/100\n",
      "323/323 [==============================] - 37s 114ms/step - loss: 0.1437\n",
      "Epoch 44/100\n",
      "323/323 [==============================] - 36s 112ms/step - loss: 0.1155\n",
      "Epoch 45/100\n",
      "323/323 [==============================] - 37s 113ms/step - loss: 0.1320\n",
      "Epoch 46/100\n",
      "323/323 [==============================] - 37s 114ms/step - loss: 0.1246\n",
      "Epoch 47/100\n",
      "177/323 [===============>..............] - ETA: 16s - loss: 0.1146"
     ]
    }
   ],
   "source": [
    "### Treinar o modelo\n",
    "modelo = treinar_rede_neural()\n",
    "modelo.save_weights('modelo_treinado.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obter_sequencias_entrada(notas, nomes_tons, n_vocab):\n",
    "    \n",
    "    # mapear entre notas e números e vice-versa\n",
    "    nota_para_inteiro = dict((nota, numero) for numero, nota in enumerate(nomes_tons))\n",
    "\n",
    "    comprimento_sequencia = 100\n",
    "    entrada_rede = []\n",
    "    for i in range(0, len(notas) - comprimento_sequencia, 1):\n",
    "        sequencia_entrada = notas[i:i + comprimento_sequencia]\n",
    "        entrada_rede.append([nota_para_inteiro[char] for char in sequencia_entrada])\n",
    "    \n",
    "    entrada_rede = np.reshape(entrada_rede, (len(entrada_rede), comprimento_sequencia, 1))\n",
    "    \n",
    "    return entrada_rede\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_notas(modelo, entrada_rede, nomes_tons, n_vocab, temperatura=2.0):\n",
    "    \n",
    "    # Escolher um número inteiro aleatório\n",
    "    inicio = np.random.randint(0, len(entrada_rede)-1)\n",
    "\n",
    "    inteiro_para_nota = dict((numero, nota) for numero, nota in enumerate(nomes_tons))\n",
    "    \n",
    "    # Escolher uma sequência aleatória da entrada como ponto de partida para a previsão\n",
    "    padrao = list(entrada_rede[inicio])\n",
    "    resultado_predicao = []\n",
    "    \n",
    "    print('Gerando notas........')\n",
    "\n",
    "    # Gerar 300 notas\n",
    "    for indice_nota in range(300):\n",
    "        entrada_predicao = np.reshape(padrao, (1, len(padrao), 1))\n",
    "        padrao = np.array(padrao)\n",
    "        entrada_predicao = entrada_predicao / float(n_vocab)\n",
    "\n",
    "        # Ajuste da temperatura\n",
    "        predicao = modelo.predict(entrada_predicao, verbose=0)[0]\n",
    "        predicao = np.log(predicao) / temperatura\n",
    "        exp_preds = np.exp(predicao)\n",
    "        predicao = exp_preds / np.sum(exp_preds)\n",
    "\n",
    "        # Escolha aleatória com base nas probabilidades ajustadas\n",
    "        indice = np.random.choice(len(predicao), p=predicao)\n",
    "        resultado = inteiro_para_nota[indice]\n",
    "\n",
    "        # Armazenar a saída prevista\n",
    "        resultado_predicao.append(resultado)\n",
    "\n",
    "        padrao = np.append(padrao, indice)\n",
    "        padrao = padrao[1:]\n",
    "\n",
    "    print('Notas geradas...')\n",
    "    print(resultado_predicao)\n",
    "    return resultado_predicao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_midi(resultado_predicao):\n",
    "    \n",
    "    offset = 0\n",
    "    notas_saida = []\n",
    "\n",
    "    # criar objetos de nota e acorde com base nos valores gerados pelo modelo\n",
    "    for padrao in resultado_predicao:\n",
    "        if ('.' in padrao) or padrao.isdigit():\n",
    "            notas_no_acorde = padrao.split('.')\n",
    "            notas = []\n",
    "            for nota_atual in notas_no_acorde:\n",
    "                nova_nota = note.Note(int(nota_atual))\n",
    "                nova_nota.storedInstrument = instrument.Piano()\n",
    "                notas.append(nova_nota)\n",
    "            novo_acorde = chord.Chord(notas)\n",
    "            novo_acorde.offset = offset\n",
    "            notas_saida.append(novo_acorde)\n",
    "        # padrao é uma nota\n",
    "        else:\n",
    "            nova_nota = note.Note(padrao)\n",
    "            nova_nota.offset = offset\n",
    "            nova_nota.storedInstrument = instrument.Piano()\n",
    "            notas_saida.append(nova_nota)\n",
    "\n",
    "        # aumentar o offset a cada iteração para que as notas não se sobreponham\n",
    "        offset += 0.5\n",
    "\n",
    "    fluxo_midi = stream.Stream(notas_saida)\n",
    "    \n",
    "    print('Salvando arquivo de saída como midi....')\n",
    "\n",
    "    fluxo_midi.write('midi', fp='saida_teste5.mid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    \"\"\" Generate a piano midi file \"\"\"\n",
    "    #load the notes used to train the model\n",
    "    with open('data/notes', 'rb') as filepath:\n",
    "        notes = pickle.load(filepath)\n",
    "\n",
    "    # Get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "    # Get all pitch names\n",
    "    n_vocab = len(set(notes))\n",
    "    \n",
    "    print('Initiating music generation process.......')\n",
    "    \n",
    "    network_input = get_inputSequences(notes, pitchnames, n_vocab)\n",
    "    normalized_input = network_input / float(n_vocab)\n",
    "    model = create_network(normalized_input, n_vocab)\n",
    "    print('Loading Model weights.....')\n",
    "    model.load_weights('./modelo_teste.h5')\n",
    "    print('Model Loaded')\n",
    "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
    "    create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating music generation process.......\n",
      "Loading Model weights.....\n",
      "Model Loaded\n",
      "Generating notes........\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_16588\\1127633650.py:22: RuntimeWarning: divide by zero encountered in log\n",
      "  prediction = np.log(prediction) / temperature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes Generated...\n",
      "['4.6.11', '2.6.9', '2.6.9', '2.5', '5.10', '2.5', '5.10', '10.2.5', '7.10', '2.7', '7.10', '2.7', 'G4', '4.6', 'A3', '4.6', 'A3', '4.6', 'A3', '2.6', 'A3', 'D4', 'A3', '2.6', 'A3', '4.6', 'A3', '4.6', 'A3', '4.6', 'A3', '2.6', 'A3', '2.6', 'A3', '2.6', 'A3', '2.6.9', '5.9.0', '2.5.9', 'E-5', '2.4', 'A3', '11.2.6', 'A3', '9.1.4', '5.10', '7.9', 'A3', '2.6.9', 'A3', 'F5', 'B-3', '5.7', 'D2', 'G3', '6.9', '2.5', 'C#5', 'D2', 'C5', '6.10.1', '11.2.6', '2.5.9', 'E-6', 'A4', 'F#4', '11.2.6', '2.6.9', 'B-3', 'F#4', '5.9.0', '2.5.9', 'G4', 'G5', 'E-4', 'G4', 'G5', 'G3', 'A4', 'C6', '10.1', 'G4', '10.0', 'A4', '10.0', 'E-4', '0.2.6.8', '0.2.5', '7.10.0', 'G3', '8.10.2', '7.10.0', '7.10.0', 'A4', '1.7', '5', 'C5', 'C3', 'F#4', 'F#4', 'F#4', 'G4', '9', 'F3', '10.1', 'F3', 'E4', 'F3', 'F3', 'F4', 'C3', 'F3', 'F3', 'F3', 'A4', 'F3', 'A4', 'F3', 'F3', '10.2.5', 'F3', 'F4', 'G4', 'F4', 'B-4', 'D4', 'F3', '5', 'G4', 'E-4', 'G4', 'F4', 'F4', 'F3', 'F3', '6.9.0', '10.2.5', 'D6', 'B4', 'F3', 'F3', 'D5', 'G#4', '10.2.5', 'F3', 'F3', 'F3', 'F3', 'F3', '10.2', '3.7', 'F#3', 'F3', 'A5', '7', 'F3', 'F3', '6.8', 'F#1', 'F3', '1', 'F3', 'F3', 'C5', 'C5', '2.6', '1', 'G#2', 'D3', '6.11', 'E5', 'G6', 'G5', 'F5', 'G3', 'C6', '2.5', 'B3', 'G5', 'F5', '5.9.0', '2.6', 'C3', 'G#5', 'C#4', 'B-4', 'G3', 'C5', 'C#4', 'G3', 'C#4', '2.5.8.11', '0.3.5', 'F2', 'G#3', 'G5', 'G5', 'F5', 'B-3', 'D3', 'B-4', 'D5', '1', 'C5', '1.7', '4.6.10', '0.2.6.8', 'E-6', '3.5.7', '5.10', 'D5', '5.9', 'D3', '10.1.4.6', '10.2', '6.9', 'F6', '6.9', 'A3', 'F4', '10', '2.6', 'A3', '6.9.1', '0.1', 'G5', 'G5', 'G5', 'F5', '8.1', 'C6', 'A5', 'G#5', '3.5.7', 'F6', '10.2', 'B2', '10.2', '2.6', '4.9', 'F3', '10.2.5', 'B4', 'F5', '8.10.2', '2.5', '5.7.0', 'F3', 'F3', 'E-4', 'F3', 'F5', '5.10', 'F3', 'F3', 'D3', 'D5', 'G5', 'F3', 'C5', 'C5', 'B-2', 'F3', 'C5', 'G#5', 'A4', 'C#5', '5.9', '10.2', 'F5', 'F5', '9.1.4', '9.0', 'G5', '5.10', 'C#2', '9.0.3', '7', '10.0', 'D5', 'F3', 'G5', 'F#4', 'C6', '6.8', '6.8', 'F5', 'G5', 'D6', 'F#5', '6.11', 'F3', 'C4', '9.0.3', '3.7.10', 'F2', '2.5.9', '11.2', '2.5']\n",
      "Saving Output file as midi....\n"
     ]
    }
   ],
   "source": [
    "\n",
    "generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file test_output4.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "play.play_midi('test_output4.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
